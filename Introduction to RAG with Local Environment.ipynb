{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d081c863-1883-4566-9f11-7f4f06d9485c",
   "metadata": {},
   "source": [
    "![Header](https://raw.githubusercontent.com/eliyantojoko/pyjo_july_25/main/Header%20Notebook.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4251dc86-1ddb-4418-a001-d132089a3e94",
   "metadata": {},
   "source": [
    "**Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a0c1aa-09f2-4d60-a51b-b771ada91860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82b426-4493-49f1-86d3-b0db9ae877bb",
   "metadata": {},
   "source": [
    "# What is Retrieval Augmented Generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9864e-b1bd-47e2-ac4a-8f7da7a92c9c",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) is a technique that combines retrieval-based and generation-based approaches in natural language processing (NLP), particularly in question answering or chatbot systems. It allows a language model to generate more accurate and up-to-date responses by first retrieving relevant information from an external knowledge source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d117849-bc8b-461c-9e7e-7bd9664472d6",
   "metadata": {},
   "source": [
    "![RAG Diagram](https://raw.githubusercontent.com/eliyantojoko/pyjo_july_25/main/RAG%20Diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e8b63-d5ff-4558-b9a5-9ff67f900985",
   "metadata": {},
   "source": [
    "## Store document in PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf58930e-c978-4fd2-845d-1db63d8047f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load PDF data ---\n",
    "loader = PyPDFLoader(\"JOKO ELIYANTO - CV.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7df2f842-dc52-4003-a174-215b00c873f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Split them into a chunk ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e6a02f1-c808-4d42-946a-02b6208243d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'JOKO ELIYANTO', 'source': 'JOKO ELIYANTO - CV.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='JOKO  ELIYANTO  \\n \\nData\\n \\nScientist\\n \\nhttps://github.com/jokoeliyanto \\n \\nIdentity  \\nAddress  :  RT  04,  Seropan  3,  Muntuk,  Dlingo,  Bantul,  D.I.  Yogyakarta,  55783  \\nMobile\\n \\n \\n:\\n \\n+62\\n \\n821\\n \\n8311\\n \\n2655\\n Email   :  jokoeliyanto@gmail.com Work  Email  :  joko@temandata.com GitHub  : https://github.com/jokoeliyanto  LinkedIn  : https://www.linkedin.com/in/joko-eliyanto-23a1b6143 \\n \\nProfessional  Summary'),\n",
       " Document(metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'JOKO ELIYANTO', 'source': 'JOKO ELIYANTO - CV.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='Professional  Summary  \\nResults-driven  Data  Scientist  with  3+  years  of  experience  across  industry  applications  and  \\neducation.\\n \\nProven\\n \\ntrack\\n \\nrecord\\n \\nin\\n \\nsolving\\n \\ncomplex\\n \\nproblems\\n \\nusing\\n \\ndata\\n \\nanalysis,\\n \\nvisualization,\\n \\nand\\n \\nmachine\\n \\nlearning.\\n \\nStrong\\n \\nacademic\\n \\nbackground\\n \\nin\\n \\nMathematics,\\n \\ncomplemented\\n \\nby\\n \\nactive\\n \\nparticipation\\n \\nin\\n \\nworkshops\\n \\nand\\n \\ncertifications\\n \\nin\\n \\nstatistics,\\n \\nbig\\n \\ndata,\\n \\ndata\\n \\nmining,\\n \\nartificial\\n \\nintelligence,\\n \\ndata')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e47d395d-ee1e-42f7-9beb-944e5fb42ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Load Embedding model ---\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "\n",
    "# --- Custom wrapper for LangChain Embeddings ---\n",
    "class MultilingualEmbedding(Embeddings):\n",
    "    def __init__(self, model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", device=None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._embed(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._embed(text)\n",
    "\n",
    "    def _embed(self, text: str) -> List[float]:\n",
    "        text = f\"passage: {text}\"  # For documents; use \"query:\" for queries\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "        return embeddings[0].cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d0c3dde-23dc-4429-9528-e8cd62599afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = MultilingualEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c908c0bb-5663-4ec0-90ab-fb2c739d90c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- 4. Simpan ke Vector DB (PostgreSQL + pgvector) ---\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    collection_name=\"je_cv\",\n",
    "    connection_string=\"postgresql+psycopg2://postgres:1234567890@172.24.194.113:5432/postgres\",\n",
    "    use_jsonb=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5495d1e2-6afa-4a2b-a21f-5f7e899ce34e",
   "metadata": {},
   "source": [
    "## Retrieval Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b49290b1-78b4-4a5e-8999-d31337eaf77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"alamat email Joko Eliyanto?\"\n",
    "n_results = 3\n",
    "\n",
    "res_semantic = vectorstore.similarity_search_with_relevance_scores(\n",
    "        query=query,\n",
    "        k=n_results\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7ff3277-e1cc-4045-9d65-3f9a2fbfe5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'JOKO ELIYANTO', 'source': 'JOKO ELIYANTO - CV.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='JOKO  ELIYANTO  \\n \\nData\\n \\nScientist\\n \\nhttps://github.com/jokoeliyanto \\n \\nIdentity  \\nAddress  :  RT  04,  Seropan  3,  Muntuk,  Dlingo,  Bantul,  D.I.  Yogyakarta,  55783  \\nMobile\\n \\n \\n:\\n \\n+62\\n \\n821\\n \\n8311\\n \\n2655\\n Email   :  jokoeliyanto@gmail.com Work  Email  :  joko@temandata.com GitHub  : https://github.com/jokoeliyanto  LinkedIn  : https://www.linkedin.com/in/joko-eliyanto-23a1b6143 \\n \\nProfessional  Summary'),\n",
       "  0.4588559343476486),\n",
       " (Document(metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'JOKO ELIYANTO', 'source': 'JOKO ELIYANTO - CV.pdf', 'total_pages': 5, 'page': 1, 'page_label': '2'}, page_content='●  Developed  business  dashboards  with  Tableau  to  support  executive  decision-making  for  \\nBMHS.\\n \\n ●  Built  machine  learning  models  to  automate  and  optimize  data  standardization  processes  \\nwithin\\n \\nthe\\n \\ndata\\n \\npipeline.\\n \\n ●  Designed  and  implemented  the  Early  Warning,  Alert,  and  Response  System  dashboard  \\nfor\\n \\nAIHSP\\n \\nusing\\n \\nSQL,\\n \\nPython,\\n \\nand\\n \\nKibana,\\n \\nbased\\n \\non\\n \\npilot\\n \\ndata\\n \\nfrom\\n \\nBali\\n \\nProvince\\n \\nHealth\\n \\nDepartment.'),\n",
       "  0.3324468832542249),\n",
       " (Document(metadata={'producer': 'Skia/PDF m140 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'JOKO ELIYANTO', 'source': 'JOKO ELIYANTO - CV.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='into\\n \\nactionable\\n \\ninsights\\n \\nthat\\n \\ndrive\\n \\nstrategic\\n \\nbusiness\\n \\ndecisions.\\n \\nRecently,\\n \\nalso\\n \\ninvolved\\n \\nin\\n \\nthe\\n \\ndevelopment\\n \\nof\\n \\nan\\n \\nAI-powered\\n \\nchatbot\\n \\nusing\\n \\nLarge\\n \\nLanguage\\n \\nModels\\n \\n(LLM)\\n \\nintegrated\\n \\nwith\\n \\nRetrieval-Augmented\\n \\nGeneration\\n \\n(RAG)\\n \\nframeworks\\n \\nto\\n \\nenhance\\n \\ncontextual\\n \\nunderstanding\\n \\nand\\n \\nresponse\\n \\naccuracy.\\n \\n \\nExperience   \\nFulltime Data  Scientist  –  Teman  Data  \\n \\nAugust\\n \\n2021\\n \\n–\\n \\nPresent'),\n",
       "  0.32584428921146513)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_semantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fa831-fe0f-46c6-992a-90ab2111b777",
   "metadata": {},
   "source": [
    "## Perform RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93c3a3eb-d2d6-4399-9bc6-aeaf8bf93f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI  \n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    openai_api_key=\"lm-studio\",  \n",
    "    model=\"nama-model-dari-lm-studio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a035a7fd-5697-4af2-957c-c0851be76592",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",  \n",
    "    search_kwargs={\n",
    "        \"k\": 3,                                \n",
    "        \"score_threshold\": 0.3             \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4f2a807-208e-4862-aa57-f85402507e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcda1d8c-39d1-4cde-a1e1-b917cb3daaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jokoeliyanto@gmail.com\n"
     ]
    }
   ],
   "source": [
    "query = \"alamat email Joko Eliyanto?\"\n",
    "response = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4e2ce-2648-4cf8-8975-3242fb92feca",
   "metadata": {},
   "source": [
    "### References "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ba3bf-6fbd-44ac-b327-2d0b3786fea1",
   "metadata": {},
   "source": [
    "https://medium.com/data-science/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2\n",
    "\n",
    "https://python.langchain.com/docs/concepts/rag/\n",
    "\n",
    "https://python.langchain.com/docs/concepts/retrievers/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
